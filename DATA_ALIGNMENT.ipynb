{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from dtaidistance import dtw as dtw_lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento dos Dados com Funções de Alinhamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input(*signals, path, max=100, min=10):\n",
    "    input = {}\n",
    "    gloss = pd.read_csv('glossary.csv')\n",
    "    signals = signals if signals else gloss['SIGNAL'].values\n",
    "    for signal in signals:\n",
    "        dfs = []\n",
    "        for root, _, files in os.walk(path):\n",
    "            for file in files:\n",
    "                if file.endswith('.parquet') and signal in file:\n",
    "                    df = pd.read_parquet(os.path.join(root, file)).fillna(0)\n",
    "                    if len(df) > max:\n",
    "                        df = pd.DataFrame({column: np.interp(np.linspace(0, 1, max), np.linspace(0, 1, len(df)), df[column].values) for column in df.columns})\n",
    "                    if len(df) > min:\n",
    "                        dfs.append(df)\n",
    "        input[signal] = dfs\n",
    "    return input\n",
    "\n",
    "def label_encoder(labels, path='glossary.csv'):\n",
    "    gloss = pd.read_csv(path)\n",
    "    return [int(gloss.loc[gloss['SIGNAL'] == label, 'ID'].values[0]) for label in labels]\n",
    "\n",
    "def padding(input):\n",
    "    X, y = [], []\n",
    "    length = max([max([df.shape[0] for df in dfs]) for dfs in input.values()])\n",
    "    for label, dfs in input.items():\n",
    "        for df in dfs:\n",
    "            padded_data = np.pad(df.values, ((0, length - df.shape[0]), (0, 0)), 'constant')\n",
    "            X.append(padded_data)\n",
    "            y.append(label)        \n",
    "    X = torch.tensor(np.array(X), dtype=torch.float32)\n",
    "    y = torch.tensor(np.array(label_encoder(y)), dtype=torch.long)\n",
    "    return X, y\n",
    "\n",
    "def interpolate(input):\n",
    "    X, y = [], []\n",
    "    length = int(round(np.mean([len(df) for dfs in input.values() for df in dfs])))\n",
    "    for label, dfs in input.items():\n",
    "        for df in dfs:\n",
    "            if len(df) == length:\n",
    "                X.append(df.values)\n",
    "            else:\n",
    "                X.append(pd.DataFrame({column: np.interp(np.linspace(0, 1, length), np.linspace(0, 1, len(df)), df[column].values) for column in df.columns}).values)\n",
    "            y.append(label)\n",
    "    X = torch.tensor(np.array(X), dtype=torch.float32)\n",
    "    y = torch.tensor(np.array(label_encoder(y)), dtype=torch.long)\n",
    "    return X, y\n",
    "\n",
    "def dtw(input):\n",
    "    X, y = [], []\n",
    "    length = int(round(np.mean([len(df) for dfs in input.values() for df in dfs])))\n",
    "    for label, dfs in input.items():\n",
    "        for df in dfs:\n",
    "            X.append(np.array([[df.values[i, col] if i < len(df.values) else df.values[-1, col] for i, _ in dtw_lib.warping_path(np.linspace(0, 1, len(df.values)), np.linspace(0, 1, length))] for col in range(df.values.shape[1])]).T[:length])\n",
    "            y.append(label)\n",
    "    X = torch.tensor(np.array(X), dtype=torch.float32)\n",
    "    y = torch.tensor(np.array(label_encoder(y)), dtype=torch.long)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset de Tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignActionDataset(Dataset):\n",
    "    def __init__(self, input, method:str):\n",
    "        self.X, self.y = method(input)\n",
    "        self.shape = tuple(self.X.shape)\n",
    "        self.labels = list(set(np.array(self.y)))\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = 'DATASET/LANDMARKS'\n",
    "OUTPUT_PATH = 'DATASET/TENSORS'\n",
    "\n",
    "input = get_input(path=INPUT_PATH)\n",
    "interpolate_input = SignActionDataset(input, interpolate)\n",
    "torch.save(interpolate_input, f'{OUTPUT_PATH}/interpolate.pt')\n",
    "padding_input = SignActionDataset(input, padding)\n",
    "torch.save(interpolate_input, f'{OUTPUT_PATH}/padding.pt')\n",
    "dtw_input = SignActionDataset(input, dtw)\n",
    "torch.save(interpolate_input, f'{OUTPUT_PATH}/dtw.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
