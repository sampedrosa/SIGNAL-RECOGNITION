{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "class TrainingBar():\n",
    "    def __init__(self, model, train_size, val_size, epochs):\n",
    "        self.model = model\n",
    "        self.train_size = train_size\n",
    "        self.val_size = val_size\n",
    "        self.epochs = epochs\n",
    "        self.bar = tqdm(total=train_size, dynamic_ncols=True, position=0, leave=False)\n",
    "    def reset(self, epoch):\n",
    "        self.bar.set_description(f\"Epoch {epoch + 1}/{self.epochs}\")\n",
    "        self.bar.reset()\n",
    "    def update(self):\n",
    "        metrics = {}\n",
    "        metrics['ACC(train)'] = f\"{self.model.train_accuracy[-1]:.4f}\"\n",
    "        metrics['ACC(val)'] = f\"{self.model.val_accuracy[-1]:.4f}\"\n",
    "        metrics['LOSS(train)'] = f\"{self.model.train_loss[-1]:.4f}\"\n",
    "        metrics['LOSS(val)'] = f\"{self.model.val_loss[-1]:.4f}\"\n",
    "        metrics['DIFF'] = f\"{(self.model.train_accuracy[-1]-self.model.train_accuracy[-2]+self.model.val_accuracy[-1]-self.model.val_accuracy[-2])/2:.4f}\"\n",
    "        self.bar.set_postfix(metrics)\n",
    "        self.bar.update(1)\n",
    "    def display(self):\n",
    "        self.update()\n",
    "        print(self.bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sign Action Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignActionTransformer(nn.Module):\n",
    "    def __init__(self, dataset:Dataset, heads, layers, dim_feedforward, dropout):\n",
    "        super(SignActionTransformer, self).__init__()\n",
    "        self.dataset = dataset\n",
    "        self.heads = heads\n",
    "        self.layers = layers\n",
    "        self.dim_feedforward = dim_feedforward\n",
    "        self.dropout = dropout\n",
    "        self.embedding = nn.Linear(dataset.shape[2], dataset.shape[2])\n",
    "        self.positional_embedding = nn.Parameter(torch.rand(dataset.shape[1], dataset.shape[2]))\n",
    "        transformer_layer = nn.TransformerEncoderLayer(d_model=dataset.shape[2], nhead=heads, dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(transformer_layer, num_layers=layers)\n",
    "        self.feedforward = nn.Sequential(nn.Linear(dataset.shape[2], dim_feedforward), nn.ReLU(), nn.Dropout(dropout), nn.Linear(dim_feedforward, dataset.shape[2]))\n",
    "        self.multihead_attention = nn.MultiheadAttention(embed_dim=dataset.shape[2], num_heads=heads, dropout=dropout, batch_first=True)\n",
    "        self.layer_norm = nn.LayerNorm(dataset.shape[2])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(dataset.shape[2], len(dataset.labels))\n",
    "        self.train_loss, self.val_loss, self.train_accuracy, self.val_accuracy = [0, 0], [0, 0], [0, 0], [0, 0]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x + self.positional_embedding.unsqueeze(0).expand(x.size(0), -1, -1)\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.dropout(x)\n",
    "        att, _ = self.multihead_attention(x, x, x)\n",
    "        att = self.feedforward(att)\n",
    "        x = x + att\n",
    "        x = x.sum(dim=1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_norm(x)\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def validation(self, max, threshold):\n",
    "        if self.train_accuracy[-1] >= max and self.val_accuracy[-1] >= max:\n",
    "            return True\n",
    "        if all(v < 0.9 for v in self.train_accuracy) and len(self.train_accuracy) > 20:\n",
    "            return True\n",
    "        return np.var(self.train_accuracy[-5:]) <= threshold\n",
    "    \n",
    "    def graph(self, save_name=''):\n",
    "        tacc, vacc = self.train_accuracy, self.train_accuracy\n",
    "        tlos, vlos = [i if (i <= 1.0 and i != 0.0) else 1.0 for i in self.train_loss], [i if (i <= 1.0 and i != 0.0) else 1.0 for i in self.val_loss]\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        plt.plot(range(1, len(tacc) + 1), tacc, label='Acurácia de Treino')\n",
    "        plt.plot(range(1, len(vacc) + 1), vacc, label='Acurácia de Validação')\n",
    "        plt.plot(range(1, len(tlos) + 1), tlos, label='Perda de Treino')\n",
    "        plt.plot(range(1, len(vlos) + 1), vlos, label='Perda de Validação')\n",
    "        plt.xlabel('Épocas')\n",
    "        plt.ylabel('Valor')\n",
    "        plt.title('Métricas por Épocas')\n",
    "        plt.legend(loc='center right', bbox_to_anchor=(1, 0.7), fontsize=12, frameon=True, fancybox=True, shadow=True)\n",
    "        plt.grid(True)\n",
    "        if save_name:\n",
    "            plt.savefig(f'OUTPUT/GRAPHS/{save_name}.png', format='png', dpi=500)\n",
    "        plt.show()\n",
    "    \n",
    "    def save_model(self, name:str):\n",
    "        torch.save(self, f'OUTPUT/MODELS/{name}.pth')\n",
    "\n",
    "    def train_model(self, epochs, batch_size, learning_rate, weight_decay, max=0.99, threshold=1e-6, train_ratio=0.8):\n",
    "        train_dataset, val_dataset = random_split(self.dataset, [int(train_ratio * len(self.dataset)), len(self.dataset) - int(train_ratio * len(self.dataset))])\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        bar = TrainingBar(model=self, train_size=len(train_loader), val_size=len(val_loader), epochs=epochs)\n",
    "        for epoch in range(epochs):\n",
    "            bar.reset(epoch)\n",
    "            self.train()\n",
    "            sum_loss = 0\n",
    "            all_train_preds, all_train_labels, all_val_preds, all_val_labels = [], [], [], []\n",
    "            for batch_data, batch_labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(batch_data)\n",
    "                loss = criterion(outputs, batch_labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_train_preds.extend(preds.cpu().numpy())\n",
    "                all_train_labels.extend(batch_labels.cpu().numpy())\n",
    "                sum_loss += loss.item()\n",
    "                bar.update()\n",
    "            sum_loss = 0\n",
    "            self.eval()\n",
    "            with torch.no_grad():\n",
    "                for batch_data, batch_labels in val_loader:\n",
    "                    outputs = self(batch_data)\n",
    "                    loss = criterion(outputs, batch_labels)\n",
    "                    sum_loss += loss.item()\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    all_val_preds.extend(predicted.cpu().numpy())\n",
    "                    all_val_labels.extend(batch_labels.cpu().numpy())\n",
    "            self.train_loss.append(sum_loss / len(train_loader))\n",
    "            self.val_loss.append(sum_loss / len(val_loader))\n",
    "            self.train_accuracy.append(accuracy_score(all_train_labels, all_train_preds))\n",
    "            self.val_accuracy.append(accuracy_score(all_val_labels, all_val_preds))\n",
    "            if self.validation(max, threshold):\n",
    "                break\n",
    "        bar.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH = 16\n",
    "MAX = 0.995\n",
    "HEADS = 86\n",
    "LAYERS = 8\n",
    "DFF = 2752\n",
    "DROPOUT = 0.1\n",
    "LR = 9e-5\n",
    "WD = 2e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = torch.load(\"OUTPUT/TENSORS/interpolate.pt\", weights_only=False)\n",
    "model1 = SignActionTransformer(dataset1, heads=HEADS, layers=LAYERS, dim_feedforward=DFF, dropout=DROPOUT)\n",
    "model1.train_model(epochs=EPOCHS, batch_size=BATCH, learning_rate=LR, weight_decay=WD, max=MAX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = torch.load(\"OUTPUT/TENSORS/padding.pt\", weights_only=False)\n",
    "model2 = SignActionTransformer(dataset2, heads=HEADS, layers=LAYERS, dim_feedforward=DFF, dropout=DROPOUT)\n",
    "model2.train_model(epochs=EPOCHS, batch_size=BATCH, learning_rate=LR, weight_decay=WD, max=MAX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3 = torch.load(\"OUTPUT/TENSORS/dtw.pt\", weights_only=False)\n",
    "model3 = SignActionTransformer(dataset3, heads=HEADS, layers=LAYERS, dim_feedforward=DFF, dropout=DROPOUT)\n",
    "model3.train_model(epochs=EPOCHS, batch_size=BATCH, learning_rate=LR, weight_decay=WD, max=MAX)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
